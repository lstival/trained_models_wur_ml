{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be2147a3",
      "metadata": {
        "id": "be2147a3"
      },
      "source": [
        "# Transfer Learning from Time Series to Images\n",
        "\n",
        "In this notebook, we will explore the application of transfer learning techniques to classify time series data by converting them into image-like representations. We will utilize pre-trained convolutional neural networks (CNNs) to extract features from these images and fine-tune the models for our specific classification task.\n",
        "\n",
        "At the end of this notebook, you will have a trained model capable of classifying time series data based on their image representations using transfer learning.\n",
        "\n",
        "The tasks its to implement the following steps:\n",
        "1. Convert time series data into image-like matrices (e.g., recurrence plots).\n",
        "2. Create a custom PyTorch dataset to load the images and labels.\n",
        "3. Implement transfer learning using a pre-trained CNN (e.g., ResNet).\n",
        "4. Train the model on the training dataset and validate it on the validation dataset.\n",
        "\n",
        "The itens 3 and 4 should be done by you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69aea8aa",
      "metadata": {
        "id": "69aea8aa"
      },
      "outputs": [],
      "source": [
        "# Core utilities\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "# Data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine learning helpers\n",
        "from pyts.image import RecurrencePlot\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "plt.style.use(\"default\")\n",
        "sns.set_palette(\"husl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25c202bb",
      "metadata": {
        "id": "25c202bb"
      },
      "source": [
        "## Download Data (Colab)\n",
        "\n",
        "Using the Colab environment, we can download the dataset directly from a provided URL. The dataset contains time series data that we will later convert into image-like representations for our classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b061a5fa",
      "metadata": {
        "id": "b061a5fa"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Define the URL of the zip file\n",
        "# zip_file_url = \"https://drive.google.com/uc?export=download&id=1fQdEogfDxmPU3Fo5j42uP68WQpQzXfU9\"\n",
        "\n",
        "# # Define the destination directory in your mounted Google Drive\n",
        "# # Make sure this path exists and is where you want to save the unzipped files\n",
        "# destination_directory = \"/content/drive/MyDrive/Itirapina/guigues/features/features/rgb/features/rgb\"\n",
        "\n",
        "# # Create the destination directory if it doesn't exist\n",
        "# !mkdir -p {destination_directory}\n",
        "\n",
        "# # Define the path to save the downloaded zip file\n",
        "# download_path = f\"{destination_directory}/data.zip\"\n",
        "\n",
        "# # Use wget to download the zip file\n",
        "# # The 'uc?export=download&id=' part is a common way to get a direct download link for GDrive files\n",
        "# print(f\"Downloading {zip_file_url} to {download_path}...\")\n",
        "# !wget --no-check-certificate '{zip_file_url}' -O '{download_path}'\n",
        "\n",
        "# # Unzip the downloaded file into the destination directory\n",
        "# print(f\"\\nUnzipping {download_path} to {destination_directory}...\")\n",
        "# !unzip -o '{download_path}' -d '{destination_directory}'\n",
        "\n",
        "# print(\"\\nDownload and extraction complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9de50758",
      "metadata": {
        "id": "9de50758"
      },
      "source": [
        "## Download Data (Personal Computer)\n",
        "\n",
        "Using a personal computer, download the dataset from the provided Google Drive link and extract it to your working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28a59c84",
      "metadata": {
        "id": "28a59c84"
      },
      "outputs": [],
      "source": [
        "# # Windows-friendly download + unzip (no Colab, no shell commands)\n",
        "# # Change destination_directory if you prefer another folder on your machine\n",
        "# destination_directory = Path.home() / \"Downloads\" / \"Itirapina\" / \"guigues\" / \"features\" / \"features\" / \"rgb\" / \"features\" / \"rgb\"\n",
        "# destination_directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# zip_file_url = \"https://drive.google.com/uc?export=download&id=1fQdEogfDxmPU3Fo5j42uP68WQpQzXfU9\"\n",
        "# download_path = destination_directory / \"data.zip\"\n",
        "\n",
        "# print(f\"Downloading {zip_file_url} to {download_path} ...\")\n",
        "# with requests.get(zip_file_url, stream=True, allow_redirects=True) as r:\n",
        "#     r.raise_for_status()\n",
        "#     total = int(r.headers.get(\"content-length\", 0))\n",
        "#     with open(download_path, \"wb\") as f, tqdm(total=total, unit=\"B\", unit_scale=True, desc=\"Downloading\", ncols=80) as pbar:\n",
        "#         for chunk in r.iter_content(chunk_size=8192):\n",
        "#             if chunk:\n",
        "#                 f.write(chunk)\n",
        "#                 pbar.update(len(chunk))\n",
        "\n",
        "# print(f\"Extracting {download_path} to {destination_directory} ...\")\n",
        "# with zipfile.ZipFile(download_path, \"r\") as zf:\n",
        "#     zf.extractall(destination_directory)\n",
        "\n",
        "# print(\"Download and extraction complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a80f8644",
      "metadata": {
        "id": "a80f8644"
      },
      "source": [
        "## Load Spectral Data\n",
        "Read the plant spectra stored as text files, preprocess them, and split into training, validation, and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d724515e",
      "metadata": {
        "id": "d724515e"
      },
      "outputs": [],
      "source": [
        "def load_spectral_data(directory):\n",
        "    data_path = Path(directory)\n",
        "    files = sorted(data_path.glob(\"*.txt\"))\n",
        "    if not files:\n",
        "        raise FileNotFoundError(f\"No .txt files found in {directory}\")\n",
        "    frames = []\n",
        "    for file in files:\n",
        "        frame = pd.read_csv(\n",
        "            file, sep=r'\\s+',\n",
        "            header=None, engine=\"python\"\n",
        "        )\n",
        "        frame[\"filename\"] = file.name\n",
        "        frames.append(frame)\n",
        "    return pd.concat(frames, ignore_index=True)\n",
        "\n",
        "df = load_spectral_data(destination_directory / \"features\" / \"rgb\")\n",
        "print(f\"Loaded {len(df)} samples from {df['filename'].nunique()} files\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bded5202",
      "metadata": {
        "id": "bded5202"
      },
      "source": [
        "## Parse Species Info\n",
        "Parse the species information from the filenames. In this way, we can assign labels to each spectrum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2b10499",
      "metadata": {
        "id": "a2b10499"
      },
      "outputs": [],
      "source": [
        "def extract_species_and_channel(filename):\n",
        "    base_name = filename.replace('.txt', '')\n",
        "    if '-' in base_name:\n",
        "        channel = base_name.split('-')[-1]\n",
        "    else:\n",
        "        channel = base_name[-1]\n",
        "    if '.' in base_name:\n",
        "        species_part = base_name.split('.', 1)[1]\n",
        "        if '_' in species_part:\n",
        "            species = species_part.split('_')[0]\n",
        "        elif '-' in species_part:\n",
        "            species = species_part.split('-')[0]\n",
        "        else:\n",
        "            species = species_part\n",
        "    else:\n",
        "        species = 'unknown'\n",
        "    return species, channel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66a31eee",
      "metadata": {
        "id": "66a31eee"
      },
      "source": [
        "From the filenames, we can extract the species names and create a mapping from species names to integer labels. This will allow us to convert the species information into numerical labels that can be used for training the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4fc1464",
      "metadata": {
        "id": "c4fc1464"
      },
      "outputs": [],
      "source": [
        "df[[\"species\", \"channel\"]] = df[\"filename\"].apply(lambda name: pd.Series(extract_species_and_channel(name)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "514b67d5",
      "metadata": {
        "id": "514b67d5"
      },
      "source": [
        "Each channel of the image will correspond to a different spectral band. In this case, we will use only the red, green and blue channels, which correspond to specific wavelength ranges in the visible spectrum. So we create one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16e25233",
      "metadata": {
        "id": "16e25233"
      },
      "outputs": [],
      "source": [
        "df_red = df[df['channel'] == 'R'].copy()\n",
        "df_green = df[df['channel'] == 'G'].copy()\n",
        "df_blue = df[df['channel'] == 'B'].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b57c451c",
      "metadata": {
        "id": "b57c451c"
      },
      "source": [
        "Looking for the distribution of classes in the training set to compute balanced class weights for the loss function. Also, split the dataset to be balanced across classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0067b1ec",
      "metadata": {
        "id": "0067b1ec"
      },
      "outputs": [],
      "source": [
        "print(f\"After filtering to Green channel: {len(df_green)} samples\")\n",
        "print(f\"Number of species: {df_green['species'].nunique()}\")\n",
        "print(df_green['species'].value_counts().head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88fdccc1",
      "metadata": {
        "id": "88fdccc1"
      },
      "source": [
        "Define the minimum amount of samples per class to be included in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43d4dac6",
      "metadata": {
        "id": "43d4dac6"
      },
      "outputs": [],
      "source": [
        "amount_samples_per_class = min(df_green['species'].value_counts().head().values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb5e7873",
      "metadata": {
        "id": "bb5e7873"
      },
      "source": [
        "Realize the slice of min_samples_per_class to filter out classes with too few samples. Now we can create the datasets and dataloaders for training, validation, and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcd60f02",
      "metadata": {
        "id": "dcd60f02"
      },
      "outputs": [],
      "source": [
        "n = int(amount_samples_per_class)\n",
        "\n",
        "def _sample_group(g):\n",
        "    # deterministically take the first n rows; if the group is smaller, repeat from the start\n",
        "    if len(g) >= n:\n",
        "        return g.iloc[:n]\n",
        "    reps = n // len(g)\n",
        "    rem = n % len(g)\n",
        "    parts = [g] * reps\n",
        "    if rem:\n",
        "        parts.append(g.iloc[:rem])\n",
        "    return pd.concat(parts, ignore_index=False)\n",
        "\n",
        "df_green = df_green.groupby(\"species\", group_keys=False).apply(_sample_group).reset_index(drop=True)\n",
        "df_green = df_green.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df_red = df_red.groupby(\"species\", group_keys=False).apply(_sample_group).reset_index(drop=True)\n",
        "df_red = df_red.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df_blue = df_blue.groupby(\"species\", group_keys=False).apply(_sample_group).reset_index(drop=True)\n",
        "df_blue = df_blue.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(f\"Balanced df_green -> {n} samples per class\")\n",
        "print(df_green[\"species\"].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0eea3fe",
      "metadata": {
        "id": "b0eea3fe"
      },
      "outputs": [],
      "source": [
        "# select spectral feature columns (0..34)\n",
        "feature_cols = [col for col in df_green.columns if isinstance(col, int) and 0 <= col <= 34]\n",
        "\n",
        "# extract per-channel matrices\n",
        "X_green = df_green[feature_cols].values\n",
        "X_red = df_red[feature_cols].values\n",
        "X_blue = df_blue[feature_cols].values\n",
        "\n",
        "# ensure same number of rows per channel\n",
        "if not (X_green.shape[0] == X_red.shape[0] == X_blue.shape[0]):\n",
        "    raise ValueError(\"Row counts differ between channels; cannot concatenate along axis=1\")\n",
        "\n",
        "# build a label encoder from the union of species across channels (robust)\n",
        "label_encoder = LabelEncoder()\n",
        "all_species = np.unique(np.concatenate([df_green['species'].values, df_red['species'].values, df_blue['species'].values]))\n",
        "label_encoder.fit(all_species)\n",
        "\n",
        "# transform labels (use green labels as the canonical y since rows align)\n",
        "y = label_encoder.transform(df_green['species'].values)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# concatenate features horizontally (axis=1)\n",
        "X = np.stack([X_red, X_green, X_blue], axis=1)\n",
        "\n",
        "print(f\"Number of spectral features per channel: {len(feature_cols)}\")\n",
        "print(f\"Concatenated feature length (3 channels): {X.shape[1]}\")\n",
        "print(f\"Number of samples: {X.shape[0]}\")\n",
        "print(f\"Classes: {dict(enumerate(label_encoder.classes_))}\")\n",
        "print(f\"Number of classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb92d0e2",
      "metadata": {
        "id": "eb92d0e2"
      },
      "source": [
        "## Split and Resample\n",
        "Define the train, validation, and test splits. Create balanced class weights for the loss function. Also, realize the interpolation inside the time series.\n",
        "In this way, all times series from 35 times steps will be resized to 140 time steps. Producing images of size 140x140.\n",
        "How we have 3 bands (RGB), the final image size will be 3x140x140."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3cc0071",
      "metadata": {
        "id": "a3cc0071"
      },
      "outputs": [],
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "orig_len = X_train.shape[-1]\n",
        "new_len = orig_len * 4\n",
        "orig_x = np.arange(orig_len)\n",
        "new_x = np.linspace(0, orig_len - 1, new_len)\n",
        "\n",
        "def interpolate_matrix(X_values, orig_axis, new_axis):\n",
        "    \"\"\"\n",
        "    Interpolate X_values along the time axis.\n",
        "    Accepts X_values shaped (B, 3, T) and returns (B, 3, new_T).\n",
        "    Also supports (B, T) input for backwards compatibility.\n",
        "    \"\"\"\n",
        "    X_values = X_values.astype(float)\n",
        "    orig_axis = np.asarray(orig_axis)\n",
        "    new_axis = np.asarray(new_axis)\n",
        "\n",
        "    if X_values.ndim == 2:\n",
        "        # (B, T) -> (B, new_T)\n",
        "        B, T = X_values.shape\n",
        "        if orig_axis.size != T:\n",
        "            raise ValueError(f\"orig_axis length ({orig_axis.size}) != T ({T})\")\n",
        "        X_new = np.empty((B, new_axis.size), dtype=float)\n",
        "        for i in range(B):\n",
        "            X_new[i, :] = np.interp(new_axis, orig_axis, X_values[i, :])\n",
        "        return X_new\n",
        "\n",
        "    elif X_values.ndim == 3:\n",
        "        # (B, C, T) -> (B, C, new_T)\n",
        "        B, C, T = X_values.shape\n",
        "        if orig_axis.size != T:\n",
        "            raise ValueError(f\"orig_axis length ({orig_axis.size}) != T ({T})\")\n",
        "        flat = X_values.reshape(-1, T)                     # (B*C, T)\n",
        "        flat_new = np.empty((flat.shape[0], new_axis.size), dtype=float)\n",
        "        for i in range(flat.shape[0]):\n",
        "            flat_new[i, :] = np.interp(new_axis, orig_axis, flat[i, :])\n",
        "        return flat_new.reshape(B, C, new_axis.size)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unexpected X_values ndim; expected 2 or 3 dimensions\")\n",
        "\n",
        "X_train = interpolate_matrix(X_train, orig_x, new_x)\n",
        "X_val = interpolate_matrix(X_val, orig_x, new_x)\n",
        "X_test = interpolate_matrix(X_test, orig_x, new_x)\n",
        "feature_cols = list(range(new_len))\n",
        "\n",
        "print(f\"Interpolated feature length: {new_len}\")\n",
        "print(f\"Train/Val/Test shapes: {X_train.shape}, {X_val.shape}, {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "469134ca",
      "metadata": {},
      "source": [
        "## Data Normalization\n",
        "\n",
        "Normalizing the data using the stand deviation to produce a distribution with mean=0 and variation=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0d6bacd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Min-max normalize X_train, X_val, X_test using training-set statistics (per-channel, per-timepoint)\n",
        "eps = 1e-8\n",
        "\n",
        "# ensure float\n",
        "X_train = X_train.astype(float)\n",
        "X_val = X_val.astype(float)\n",
        "X_test = X_test.astype(float)\n",
        "\n",
        "# compute per-timepoint, per-channel min/max from training set -> shape (1, C, T)\n",
        "train_mins = X_train.min(axis=0, keepdims=True)\n",
        "train_maxs = X_train.max(axis=0, keepdims=True)\n",
        "train_range = np.maximum(train_maxs - train_mins, eps)\n",
        "\n",
        "# apply min-max normalization and clip to [0, 1]\n",
        "X_train = np.clip((X_train - train_mins) / train_range, 0.0, 1.0)\n",
        "X_val   = np.clip((X_val   - train_mins) / train_range, 0.0, 1.0)\n",
        "X_test  = np.clip((X_test  - train_mins) / train_range, 0.0, 1.0)\n",
        "\n",
        "print(\"After min-max normalization using training-set statistics:\")\n",
        "print(\"  X_train shape:\", X_train.shape, \"min:\", X_train.min().round(6), \"max:\", X_train.max().round(6))\n",
        "print(\"  X_val   shape:\", X_val.shape,   \"min:\", X_val.min().round(6),   \"max:\", X_val.max().round(6))\n",
        "print(\"  X_test  shape:\", X_test.shape,  \"min:\", X_test.min().round(6),  \"max:\", X_test.max().round(6))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb44fa85",
      "metadata": {
        "id": "bb44fa85"
      },
      "source": [
        "## Visualise Means\n",
        "After the interpolation, we can visualise the mean spectra for each class to see how they look like.\n",
        "For each dataset (train, val, test), we compute the mean spectra for each class and plot them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48339f85",
      "metadata": {
        "id": "48339f85"
      },
      "outputs": [],
      "source": [
        "def plot_dataset_class_means(ax, X_values, labels, encoder, max_classes=None):\n",
        "    unique_labels = np.unique(labels)\n",
        "    if max_classes is not None:\n",
        "        unique_labels = unique_labels[:max_classes]\n",
        "    palette = sns.color_palette(\"husl\", len(unique_labels))\n",
        "    x_axis = np.arange(X_values.shape[1])\n",
        "    for color, lbl in zip(palette, unique_labels):\n",
        "        mask = labels == lbl\n",
        "        if mask.sum() == 0:\n",
        "            continue\n",
        "        mean_curve = X_values[mask].mean(axis=0)\n",
        "        ax.plot(x_axis, mean_curve, label=f\"{encoder.classes_[lbl]} (n={mask.sum()})\", color=color, linewidth=1.8)\n",
        "    ax.set_xlabel(\"Interpolated Feature Index\")\n",
        "    ax.set_ylabel(\"Mean Spectral Value\")\n",
        "    ax.grid(alpha=0.3)\n",
        "    ax.legend(loc=\"upper right\", fontsize=\"small\")\n",
        "\n",
        "channels = [\"Red\", \"Green\", \"Blue\"]\n",
        "fig, axes = plt.subplots(len(channels), 3, figsize=(18, 12), sharey=True)\n",
        "\n",
        "for ch_idx, ch_name in enumerate(channels):\n",
        "    plot_dataset_class_means(axes[ch_idx, 0], X_train[:, ch_idx, :], y_train, label_encoder)\n",
        "    axes[ch_idx, 0].set_title(f\"Train - {ch_name}\")\n",
        "    plot_dataset_class_means(axes[ch_idx, 1], X_val[:, ch_idx, :], y_val, label_encoder)\n",
        "    axes[ch_idx, 1].set_title(f\"Validation - {ch_name}\")\n",
        "    plot_dataset_class_means(axes[ch_idx, 2], X_test[:, ch_idx, :], y_test, label_encoder)\n",
        "    axes[ch_idx, 2].set_title(f\"Test - {ch_name}\")\n",
        "\n",
        "fig.suptitle(\"Class mean spectral signatures (after interpolation) per channel\", fontsize=14)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf7fbf7f",
      "metadata": {
        "id": "cf7fbf7f"
      },
      "source": [
        "The interpolation does not changed the behavior of each class, keeping similar among the datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1b2600e",
      "metadata": {
        "id": "d1b2600e"
      },
      "source": [
        "## Recurrence Plots\n",
        "A recurrence plot (RP) is a two-dimensional graph that visualizes the recurring states of a dynamical system or time series data. It is a powerful tool for analyzing complex, nonlinear data, especially short or non-stationary time series where other methods may fail.\n",
        "We convert each time series into a recurrence plot image, which captures the temporal patterns and relationships within the data. This transformation allows us to leverage pre-trained vision models for classification tasks.\n",
        "We create recurrence plots for each spectrum in the dataset. Each recurrence plot is generated by computing the pairwise distances between time points in the time series and applying a threshold to determine recurrence.\n",
        "The recurrence plots are 140x140 pixels once the time series have 140 time steps after interpolation.\n",
        "We can visualise some examples of recurrence plots for different classes to see how they look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7990fd09",
      "metadata": {
        "id": "7990fd09"
      },
      "outputs": [],
      "source": [
        "rp = RecurrencePlot(threshold=None)\n",
        "# compute recurrence plots per-channel and then average channels into a single grayscale image\n",
        "train_rps, val_rps, test_rps = [], [], []\n",
        "for ch in range(X_train.shape[1]):  # iterate over channel dimension (axis=1)\n",
        "    X_train_c = X_train[:, ch, :]  # (B, T)\n",
        "    X_val_c = X_val[:, ch, :]\n",
        "    X_test_c = X_test[:, ch, :]\n",
        "\n",
        "    X_train_rp_c = rp.fit_transform(X_train_c)\n",
        "    X_val_rp_c = rp.transform(X_val_c)\n",
        "    X_test_rp_c = rp.transform(X_test_c)\n",
        "\n",
        "    train_rps.append(X_train_rp_c)\n",
        "    val_rps.append(X_val_rp_c)\n",
        "    test_rps.append(X_test_rp_c)\n",
        "\n",
        "# stack -> (B, C, H, W) then collapse channels by mean -> (B, H, W)\n",
        "X_train_rp = np.stack(train_rps, axis=1)\n",
        "X_val_rp = np.stack(val_rps, axis=1)\n",
        "X_test_rp = np.stack(test_rps, axis=1)\n",
        "\n",
        "print(f\"Recurrence plot shapes -> train: {X_train_rp.shape}, val: {X_val_rp.shape}, test: {X_test_rp.shape}\")\n",
        "\n",
        "n_show = min(3, X_train_rp.shape[0], X_val_rp.shape[0], X_test_rp.shape[0])\n",
        "fig, axes = plt.subplots(3, n_show, figsize=(n_show * 3, 9))\n",
        "for idx in range(n_show):\n",
        "    axes[0, idx].imshow((X_train_rp[idx].swapaxes(0, 2)*255).astype(np.uint8), origin='lower')\n",
        "    axes[0, idx].set_title(f\"Train: {label_encoder.classes_[y_train[idx]]}\")\n",
        "    axes[0, idx].axis('off')\n",
        "    axes[1, idx].imshow((X_val_rp[idx].swapaxes(0, 2)*255).astype(np.uint8), origin='lower')\n",
        "    axes[1, idx].set_title(f\"Val: {label_encoder.classes_[y_val[idx]]}\")\n",
        "    axes[1, idx].axis('off')\n",
        "    axes[2, idx].imshow((X_test_rp[idx].swapaxes(0, 2)*255).astype(np.uint8), origin='lower')\n",
        "    axes[2, idx].set_title(f\"Test: {label_encoder.classes_[y_test[idx]]}\")\n",
        "    axes[2, idx].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "931685de",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "76b254ae",
      "metadata": {
        "id": "76b254ae"
      },
      "source": [
        "## Torch Dataset\n",
        "Create a custom PyTorch dataset to load the recurrence plot images and their corresponding labels. This dataset will be used to feed data into the model during training and evaluation.\n",
        "The images are stored as numpy arrays, and the labels are stored as integers. The dataset will handle loading the images and labels, as well as any necessary transformations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4f864fe",
      "metadata": {
        "id": "d4f864fe"
      },
      "outputs": [],
      "source": [
        "class NumpyImageDataset(Dataset):\n",
        "    \"\"\"Prepares recurrence plots once so __getitem__ stays lightweight.\n",
        "    Expects X shaped (B, C, H, W). Keeps original size unless target_size is given.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X, y, target_size=None):\n",
        "        # X: numpy array (B, C, H, W) -> convert to float tensor\n",
        "        X_tensor = torch.from_numpy(X).float()  # (B, C, H, W)\n",
        "\n",
        "        # normalize per-sample per-channel over H,W\n",
        "        mins = X_tensor.amin(dim=(2, 3), keepdim=True)\n",
        "        maxs = X_tensor.amax(dim=(2, 3), keepdim=True).clamp(min=1e-6)\n",
        "        X_tensor = (X_tensor - mins) / (maxs - mins)\n",
        "\n",
        "        # optionally resize (keeps shape if target_size is None or matches current)\n",
        "        if target_size is not None and (X_tensor.shape[2], X_tensor.shape[3]) != tuple(target_size):\n",
        "            X_tensor = F.interpolate(X_tensor, size=target_size, mode='bilinear', align_corners=False)\n",
        "\n",
        "        self.images = X_tensor.contiguous()  # (B, C, H, W)\n",
        "        self.labels = torch.from_numpy(y).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.numel()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]\n",
        "\n",
        "batch_size = 32\n",
        "train_ds = NumpyImageDataset(X_train_rp, y_train)\n",
        "val_ds = NumpyImageDataset(X_val_rp, y_val)\n",
        "test_ds = NumpyImageDataset(X_test_rp, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1814a25e",
      "metadata": {
        "id": "1814a25e"
      },
      "source": [
        "### Evaluation Methods\n",
        "\n",
        "To evaluate the model's performance, we will use accuracy as the primary metric. Accuracy measures the proportion of correctly classified samples out of the total number of samples.\n",
        "Also, the F1-score will be used to provide a more comprehensive evaluation, especially in cases of class imbalance. The F1-score is the harmonic mean of precision and recall, providing a balance between the two metrics.\n",
        "And a confusion matrix will be generated to visualize the model's performance across different classes. The confusion matrix shows the number of correct and incorrect predictions for each class, allowing us to identify specific areas where the model may be struggling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60c67250",
      "metadata": {
        "id": "60c67250"
      },
      "outputs": [],
      "source": [
        "def evaluate_and_plot(model, best_state, test_loader):\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict({key: value.to(device) for key, value in best_state.items()})\n",
        "    model.eval()\n",
        "    test_preds, test_labels_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            test_preds.extend(preds.cpu().numpy())\n",
        "            test_labels_list.extend(labels.cpu().numpy())\n",
        "\n",
        "    test_acc = accuracy_score(test_labels_list, test_preds)\n",
        "    cm = confusion_matrix(test_labels_list, test_preds)\n",
        "    precision = precision_score(test_labels_list, test_preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(test_labels_list, test_preds, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(test_labels_list, test_preds, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"Precision (weighted): {precision:.4f}\")\n",
        "    print(f\"Recall (weighted):    {recall:.4f}\")\n",
        "    print(f\"F1-score (weighted):  {f1:.4f}\")\n",
        "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Plot absolute counts and row-normalized percentages side-by-side\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "    # Absolute counts\n",
        "    disp_counts = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "    disp_counts.plot(cmap='Blues', ax=axes[0], xticks_rotation=45, values_format='d')\n",
        "    axes[0].set_title(\"Confusion Matrix — counts\")\n",
        "\n",
        "    # Row-normalized percentages\n",
        "    cm_row_sums = cm.sum(axis=1, keepdims=True)\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        cm_pct = (cm.astype(float) / cm_row_sums) * 100\n",
        "    cm_pct = np.nan_to_num(cm_pct)  # replace NaNs resulting from zero rows\n",
        "\n",
        "    disp_pct = ConfusionMatrixDisplay(confusion_matrix=cm_pct, display_labels=label_encoder.classes_)\n",
        "    # draw heatmap only (no values) so our percent annotations do not overlap\n",
        "    disp_pct.plot(cmap='Blues', ax=axes[1], xticks_rotation=45, values_format=None, include_values=False)\n",
        "    axes[1].set_title(\"Confusion Matrix — row %\")\n",
        "\n",
        "    # Annotate percentage cells with one decimal and a % sign\n",
        "    for i in range(cm_pct.shape[0]):\n",
        "        for j in range(cm_pct.shape[1]):\n",
        "            axes[1].text(j, i, f\"{cm_pct[i, j]:.1f}%\", ha='center', va='center', color='black', fontsize=8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cd80493",
      "metadata": {
        "id": "6cd80493"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "aff70490",
      "metadata": {},
      "source": [
        "## Training Lines\n",
        "The code below produces a plot for compare the acc and loss of the trainind and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b650317",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_curves(list_train_loss, list_val_loss, list_train_acc, list_val_acc):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Left subplot: Training and Validation Loss\n",
        "    axes[0].plot(list_train_loss, label='Train Loss')\n",
        "    axes[0].plot(list_val_loss, label='Val Loss')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].set_title('Training and Validation Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    # Right subplot: Training and Validation Accuracy\n",
        "    axes[1].plot(list_train_acc, label='Train Accuracy')\n",
        "    axes[1].plot(list_val_acc, label='Val Accuracy')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    axes[1].set_title('Training and Validation Accuracy')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ea4ca6d",
      "metadata": {
        "id": "5ea4ca6d"
      },
      "source": [
        "## Train ResNet Head\n",
        "\n",
        "This cell provide the method train_model, will train the model layers that require gradients are True.\n",
        "In this case, only the head of the ResNet model when the transfer learning is used.\n",
        "The training will be done for a number of epochs, using the training and validation dataloaders.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac6d949f",
      "metadata": {
        "id": "ac6d949f"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, num_epochs):\n",
        "    # compute balanced class weights from training set\n",
        "    class_counts = np.bincount(y_train, minlength=num_classes)\n",
        "    print(\"Train class counts:\", dict(enumerate(class_counts)))\n",
        "    class_weights = (y_train.size) / (num_classes * class_counts.astype(float))\n",
        "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float, device=device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "    # optimize any parameters that require gradients (e.g. the new fc)\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
        "\n",
        "    list_train_loss = []\n",
        "    list_val_loss = []\n",
        "    list_train_acc = []\n",
        "    list_val_acc = []\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_state = None\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        val_running_loss = 0\n",
        "        running_corrects = 0\n",
        "        val_running_corrects = 0\n",
        "        total = 0\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} [train]\", leave=False)\n",
        "        for inputs, labels in pbar:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            running_corrects += (preds == labels).sum().item()\n",
        "            total += inputs.size(0)\n",
        "            pbar.set_postfix({\"batch_loss\": f\"{loss.item():.4f}\", \"batch_acc\": f\"{(preds == labels).float().mean().item():.4f}\"})\n",
        "        pbar.close()\n",
        "        train_loss = running_loss / total\n",
        "        train_acc = running_corrects / total\n",
        "        list_train_loss.append(train_loss)\n",
        "        list_train_acc.append(train_acc)\n",
        "\n",
        "        model.eval()\n",
        "        val_preds, val_labels = [], []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            val_running_loss = 0.0\n",
        "            val_running_corrects = 0\n",
        "            total_val = 0\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                val_loss = criterion(outputs, labels)\n",
        "                val_running_loss += val_loss.item() * inputs.size(0)\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                val_running_corrects += (preds == labels).sum().item()\n",
        "                total_val += inputs.size(0)\n",
        "            val_loss = val_running_loss / total_val\n",
        "            val_acc = val_running_corrects / total_val\n",
        "\n",
        "        list_val_acc.append(val_acc)\n",
        "        list_val_loss.append(val_loss)\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_state = {key: value.cpu() for key, value in model.state_dict().items()}\n",
        "        print(f\"Epoch {epoch}/{num_epochs} - train_loss {train_loss:.4f} - train_acc {train_acc:.4f} - val_acc {val_acc:.4f}\")\n",
        "\n",
        "    return best_state, list_train_loss, list_val_loss, list_train_acc, list_val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24e12b0e",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "628b32a4",
      "metadata": {
        "id": "628b32a4"
      },
      "source": [
        "## TO DO\n",
        "- Implement the model to realize feature extraction from the images. (Transfer Learning)\n",
        "- Create a Multi-Layer Perceptron (MLP) to be trained from scratch as Fully Connected (FC) layers of the model, or Head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c77e127",
      "metadata": {
        "id": "6c77e127"
      },
      "outputs": [],
      "source": [
        "#### CODE TO CREATE THE MODEL WITH PRETRAINED WEIGHTS\n",
        "\n",
        "#### CODE TO CHANGE / CREATE THE CLASSIFICATION LAYER\n",
        "\n",
        "model = model.to(device) # Sendto the device\n",
        "\n",
        "num_epochs = 20 # Number of epochs to train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b87abb0b",
      "metadata": {
        "id": "b87abb0b"
      },
      "outputs": [],
      "source": [
        "best_state, list_train_loss, list_val_loss, list_train_acc, list_val_acc = train_model(model, train_loader, val_loader, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9743978b",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_training_curves(list_train_loss, list_val_loss, list_train_acc, list_val_acc)\n",
        "evaluate_and_plot(model, best_state, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77f4a740",
      "metadata": {
        "id": "77f4a740"
      },
      "source": [
        "## Fine-Tune Last Layers\n",
        "\n",
        "Using the same model, we can unfreeze some of the last layers of the backbone to fine-tune them along with the head.\n",
        "- Unfreeze the last few layers of the backbone for fine-tuning.\n",
        "- Train the model with the unfrozen layers for a number of epochs.\n",
        "- Evaluate the model on the test dataset and plot the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e18f5c9e",
      "metadata": {
        "id": "e18f5c9e"
      },
      "outputs": [],
      "source": [
        "#### CODE TO CREATE THE MODEL WITH PRETRAINED WEIGHTS\n",
        "\n",
        "#### CODE TO UNFREZZE SOME LAYERS OF THE MODEL\n",
        "\n",
        "#### CODE TO CHANGE / CREATE THE CLASSIFICATION LAYER\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "best_state, list_train_loss, list_val_losss, list_train_acc, list_val_acc = train_model(model_ft, train_loader, val_loader, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5806fa83",
      "metadata": {
        "id": "5806fa83"
      },
      "outputs": [],
      "source": [
        "plot_training_curves(list_train_loss, list_val_loss, list_train_acc, list_val_acc)\n",
        "evaluate_and_plot(model_ft, best_state, test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "bepe",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
